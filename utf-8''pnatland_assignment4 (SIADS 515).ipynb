{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please add your name and University of Michagan uniqname here...\n",
    "\n",
    "NAME = 'Paul Natland'\n",
    "UMICH_UNIQNAME = 'pnatland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nACKNOWLEDGEMENTS: For this assignment, I benefited from lecture videos, searches on Stacks Overflow, and conversations on SLACK\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ACKNOWLEDGEMENTS: For this assignment, I benefited from lecture videos, searches on Stacks Overflow, and conversations on SLACK\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "828bc331fb4b474c4dc318c79e21c858",
     "grade": false,
     "grade_id": "cell-5a2075c6fc8553e4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.3.060120\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "409f037ad73b24de5435ca5034e81b2f",
     "grade": false,
     "grade_id": "cell-7dd8dd131b0c6a5d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SIADS 515 Week 4 Homework (HW4)\n",
    "\n",
    "## Background\n",
    "\n",
    "The motivation for this assignment is to **improve the efficiency of code** that finds the similarity between any two given documents.  There are many ways to calculate similarity (or distance) between two documents, but the most effective way is to represent each document as a multi-dimensional vector where each dimension corresponds to a word, and the value along that dimension is the number of times that word occurs in a document.  Let's take a look at a simplified case where we only have two dimensions:\n",
    "\n",
    "![](assets/CosineDistanceSimilarity.png)\n",
    "\n",
    "In the above diagram, Item 1 and Item 2 refer to two documents.  The angle between them (ð›³) can range from -180 to +180 degrees.  The cosine of angles, in this case, has a nice property in that the cosine of an angle of 0 degrees is 1, the cosine of an angle of 90 degrees is 0, and the cosine of an angle of 180 degrees is -1.  In other words, the cosine of the angle between the vector representation of a document behaves much like a correlation coefficient.  A cosine of 1 indicates the documents are identical, a cosine of 0 indicates the documents are independent of each other, and a cosine of -1 indicates the documents are \"opposites\" (note: the latter requires a specific setup that is beyond the scope of this course).\n",
    "\n",
    "Your task, for this assignment, is to improve the efficiency of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "523ea2670f08a68ece190b1283069754",
     "grade": false,
     "grade_id": "cell-4775a39fe80a7d8a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Steps\n",
    "\n",
    "1. Run the notebook as it is.\n",
    "1. Study each function in the code, making notes to yourself in preparation for the next step.  \n",
    "1. Annotate each function with a detailed description of what the input and output parameters are.  Provide a brief description, in your own words, of what each function does.  Use docstrings ([PEP-257](https://www.python.org/dev/peps/pep-0257/)) to document the code.\n",
    "1. Make changes to the code to improve its efficiency. \n",
    "\n",
    "Note\n",
    "  - You may [refactor](https://en.wikipedia.org/wiki/Code_refactoring) to combine functions or make other changes if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist1.py\n",
    "# Original author: Ronald L. Rivest\n",
    "# Some adaptation by Chris Teplovs and Kevyn Collins-Thompson\n",
    "#\n",
    "#\n",
    "# This program computes the \"distance\" between two text files\n",
    "# as the angle between their word frequency vectors.\n",
    "#\n",
    "# For each input file, a word-frequency vector is computed as follows:\n",
    "#    (1) the specified file is read in\n",
    "#    (2) it is converted into a list of alphanumeric \"words\"\n",
    "#        Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "#        characters.  Non-alphanumeric characters are treated as blanks.\n",
    "#        Case is not significant.\n",
    "#    (3) for each word, its frequency of occurrence is determined\n",
    "#    (4) the word/frequency lists are sorted into order alphabetically\n",
    "#\n",
    "# The \"distance\" between two vectors is the angle between them.\n",
    "# If x = (x1, x2, ..., xn) is the first vector (xi = freq of word i)\n",
    "# and y = (y1, y2, ..., yn) is the second vector,\n",
    "# then the angle between them is defined as:\n",
    "#    d(x,y) = arccos(inner_product(x,y) / (norm(x)*norm(y)))\n",
    "# where:\n",
    "#    inner_product(x,y) = x1*y1 + x2*y2 + ... xn*yn\n",
    "#    norm(x) = sqrt(inner_product(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "    # math.acos(x) is the arccosine of x.\n",
    "    # math.sqrt(x) is the square root of x.\n",
    "\n",
    "import string\n",
    "    # string.join(words,sep) takes a given list of words,\n",
    "    #    and returns a single string resulting from concatenating them\n",
    "    #    together, separated by the string sep .\n",
    "    # string.lower(word) converts word to lower-case\n",
    "\n",
    "import sys\n",
    "    # sys.exit() allows us to quit (if we can't read a file)\n",
    "\n",
    "\"\"\"New Imports\"\"\"\n",
    "from functools import lru_cache\n",
    "    #to use the @lru_cache decorator...all over the place!\n",
    "    \n",
    "import re\n",
    "    #to apply regular expressions to extract words from text (in my read_file_new function)\n",
    "\n",
    "from collections import defaultdict\n",
    "    #for better dictionary functionality (in my read_file_new function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the code originals with updated docstrings according to PEP-257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the original code with updated docstring\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"Read the text file (filename) and return a list of the lines from it.\"\"\"\n",
    "    try:\n",
    "        fp = open(filename)\n",
    "        L = fp.readlines()\n",
    "    except IOError as excObj:\n",
    "        print(str(excObj))\n",
    "        print(\"Error opening or reading input file: \" + filename)\n",
    "        sys.exit()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Read the text file (filename) and return a list of the lines from it.'\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(read_file.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the original code with updated docstring\n",
    "\n",
    "def get_words_from_line_list(L):  \n",
    "    \"\"\"Parse the given list (L) of text lines and return a list of all words found.\"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Parse the given list (L) of text lines and return a list of all words found.'\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(get_words_from_line_list.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code with updated docstring\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"Parse the give the string (line) and return a list of words in it after converting all words to lower-case.\"\"\"\n",
    "    word_list = []          # accumulates words in line\n",
    "    character_list = []     # accumulates characters in word\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list)>0:\n",
    "            word = str.join(\"\", character_list)\n",
    "            word = str.lower(word)\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = str.join(\"\", character_list)\n",
    "        word = str.lower(word)\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Parse the give the string (line) and return a list of words in it after converting all words to lower-case.'\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(get_words_from_string.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjustment based on Part 2 of assignment, using .extend()\n",
    "# def get_words_from_line_list2(L):  \n",
    "#     \"\"\"using extend \"\"\"\n",
    "#     ### Parse the given list L of text lines into words.\n",
    "#     ### Return list of all words found.\n",
    "\n",
    "#     word_list = []\n",
    "#     for line in L:\n",
    "#         words_in_line = get_words_from_string(line)\n",
    "#         word_list.extend(words_in_line)\n",
    "#     return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code with updated docstring\n",
    "\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"Parse the given list of words in word_list and return a list of lists containing the word and its frequency.\"\"\"\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Parse the given list of words in word_list and return a list of lists containing the word and its frequency.'\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(count_frequency.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code update based on part 2 of assignment\n",
    "# def count_frequency2(word_list):\n",
    "        \n",
    "#     ### Return a list giving pairs of form: (word,frequency)\n",
    "\n",
    "#     D = {}\n",
    "#     for new_word in word_list:\n",
    "#         for entry in D:\n",
    "#             if new_word in D:\n",
    "#                 D[new_word] += 1\n",
    "#                 break\n",
    "#         else:\n",
    "#             D[new_word] = 1\n",
    "#     return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code with updated docstring\n",
    "\n",
    "def insertion_sort(A):\n",
    "    \"\"\"Return the given list (A) sorted in place according to the item of index == 0.\n",
    "\n",
    "    From Cormen/Leiserson/Rivest/Stein, Introduction to Algorithms (second edition), page 17, \n",
    "    modified to adjust for fact that Python arrays use 0-indexing.\n",
    "    \"\"\"\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j-1\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Return the given list (A) sorted in place according to the item of index == 0.\\\\n\\\\n    From Cormen/Leiserson/Rivest/Stein, Introduction to Algorithms (second edition), page 17, \\\\n    modified to adjust for fact that Python arrays use 0-indexing.\\\\n    '\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(insertion_sort.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code with updated docstring\n",
    "\n",
    "def word_frequencies_for_file(filename,verbose=False):\n",
    "    \"\"\"For the give text file (filename), return an alphabetically sorted list of words contained and their frequency.\n",
    "    \n",
    "    Returns An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "    The function also prints a statement including the number of lines, the number of words, and the number of \n",
    "    distinct words in the text file (filename).\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    if verbose:\n",
    "        print(\"File\",filename,\":\", len(line_list),\"lines,\", len(word_list),\"words,\", len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'For the give text file (filename), return an alphabetically sorted list of words contained and their frequency.\\\\n    \\\\n    Returns An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\\\\n    The function also prints a statement including the number of lines, the number of words, and the number of \\\\n    distinct words in the text file (filename).\\\\n    '\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(word_frequencies_for_file.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code --- docstring needs updating\n",
    "\n",
    "def inner_product(L1,L2):\n",
    "    \"\"\"Return an inner product of the two vectors provided (L1, L2).\n",
    "    \n",
    "    Args:\n",
    "        L1: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "        L2: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "    \"\"\"\n",
    "    ### Inner product between two vectors, where vectors\n",
    "    ### are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    ### Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "    ###                        [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0\n",
    "\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Return an inner product of the two vectors provided (L1, L2).\\\\n    \\\\n    Args:\\\\n        L1: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\\\\n        L2: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\\\\n    '\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(inner_product.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code  --- docstring needs updating\n",
    "\n",
    "def vector_angle(L1,L2):\n",
    "    \"\"\"Returns the angle (in radians) between the given vectors (L1 and L2).\n",
    "    \n",
    "    The function performs a dot product of the two vectors and returns the angle between them.\n",
    "    \n",
    "    Args:\n",
    "        L1: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "        L2: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Returns the angle (in radians) between the given vectors (L1 and L2).\\\\n    \\\\n    The function performs a dot product of the two vectors and returns the angle between them.\\\\n    \\\\n    Args:\\\\n        L1: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\\\\n        L2: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\\\\n    '\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(vector_angle.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code  ---- just do updated docstring\n",
    "def document_similarity(filename_1, filename_2, verbose=True):\n",
    "    \"\"\"For each of the input text files, find the distinct words present and their frequency, vectorize that data\n",
    "    and return the angle and and cosine of the vectors.\n",
    "    \n",
    "    The function takes as input two text files, counts the word frequency in each one, vectorizes that information\n",
    "    and calculates the Cosine Similarity of the two vectors produced.  For each input text file (filename_1, filename_2)\n",
    "    the function prints the number of lines, words, and distinct words in each and, if verbose=True, also\n",
    "    prints the cosine and angle for the vectors described.\n",
    "    \"\"\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1, verbose)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2, verbose)\n",
    "    cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    # Use f-strings; see https://realpython.com/python-f-strings/ for more information\n",
    "    if verbose:\n",
    "        print(f\"The cosine between the documents is {cosine : 0.6f}.\")\n",
    "        print(f\"The angle between the documents is {math.acos(cosine) : 0.6f} radians or {math.acos(cosine)*180/math.pi : .0f} degrees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'For each of the input text files, find the distinct words present and their frequency, vectorize that data\\\\n    and return the angle and and cosine of the vectors.\\\\n    \\\\n    The function takes as input two text files, counts the word frequency in each one, vectorizes that information\\\\n    and calculates the Cosine Similarity of the two vectors produced.  For each input text file (filename_1, filename_2)\\\\n    the function prints the number of lines, words, and distinct words in each and, if verbose=True, also\\\\n    prints the cosine and angle for the vectors described.\\\\n    '\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(document_similarity.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File assets/short.t1.txt : 200 lines, 1855 words, 772 distinct words\n",
      "File assets/short.t2.txt : 200 lines, 752 words, 334 distinct words\n",
      "The cosine between the documents is  0.712533.\n",
      "The angle between the documents is  0.777694 radians or  45 degrees.\n"
     ]
    }
   ],
   "source": [
    "document_similarity('assets/short.t1.txt','assets/short.t2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is my refactored code to yield the same product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(128)\n",
    "def read_file_new(filename):\n",
    "    \"\"\"Read the text file (filename) and return a dictionary (defaultdict) with unique words and their frequency.\n",
    "    \n",
    "    Function uses regex to extract all of the words in each line of filename after converting words to lower-case.\n",
    "    It then stores the words as keys and counts their frequency in the defaultdict.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wordfreq = defaultdict(int)\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                for word in re.findall(r'[A-Za-z0-9]+', line.lower()):\n",
    "                    wordfreq[word]+=1\n",
    "        \n",
    "    except IOError as excObj:\n",
    "        print(str(excObj))\n",
    "        print(\"Error opening or reading input file: \" + filename)\n",
    "        sys.exit()\n",
    "        \n",
    "    return wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Read the text file (filename) and return a dictionary (defaultdict) with unique words and their frequency.\\\\n    \\\\n    Function uses regex to extract all of the words in each line of filename after converting words to lower-case.\\\\n    It then stores the words as keys and counts their frequency in the defaultdict.\\\\n    '\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(read_file_new.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.7 ns Â± 0.614 ns per loop (mean Â± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_file_new('assets/short.t1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.01 ms Â± 99.7 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_file_new.__wrapped__('assets/short.t1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code, just used the decorator @lru_cache\n",
    "\n",
    "@lru_cache(128)\n",
    "def inner_product(L1,L2):\n",
    "    \"\"\"Return an inner product of the two vectors provided (L1, L2).\n",
    "    \n",
    "    Args:\n",
    "        L1: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "        L2: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the original code, just used the decorator @lru_cache\n",
    "\n",
    "@lru_cache(128)\n",
    "def vector_angle(L1,L2):\n",
    "    \"\"\"Returns the angle (in radians) between the given vectors (L1 and L2).\n",
    "    \n",
    "    The function performs a dot product of the two vectors and returns the angle between them.\n",
    "    \n",
    "    Args:\n",
    "        L1: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "        L2: An alphabetically sorted list of lists that represent word frequency pairs in the format [word, freq]\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(128)\n",
    "def document_similarity_new(filename_1, filename_2, verbose=True):\n",
    "    \"\"\"For each of the input text files, find the distinct words present and their frequency, vectorize that data\n",
    "    and return the angle and and cosine of the vectors.\n",
    "    \n",
    "    The function takes as input two text files, counts the word frequency in each one, vectorizes that information\n",
    "    and calculates the Cosine Similarity of the two vectors produced.  For each input text file (filename_1, filename_2)\n",
    "    the function prints the number of lines, words, and distinct words in each and, if verbose=True, also\n",
    "    prints the cosine and angle for the vectors described.\n",
    "    \"\"\"\n",
    "    list1 = [(k,v) for k,v in read_file_new(filename_1).items()]\n",
    "    list2 = [(k,v) for k,v in read_file_new(filename_2).items()]\n",
    "    list1.sort()\n",
    "    list2.sort()\n",
    "    \n",
    "    list1_tuple = tuple(list1)\n",
    "    list2_tuple = tuple(list2)\n",
    "    \n",
    "    cosine = vector_angle(list1_tuple,list2_tuple)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"The cosine between the documents is {cosine : 0.6f}.\")\n",
    "        print(f\"The angle between the documents is {math.acos(cosine) : 0.6f} radians or{math.acos(cosine)*180/math.pi : .0f} degrees.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns the same cosine and angle as the original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine between the documents is  0.712533.\n",
      "The angle between the documents is  0.777694 radians or 45 degrees.\n"
     ]
    }
   ],
   "source": [
    "document_similarity_new('assets/short.t1.txt','assets/short.t2.txt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfomance of short text cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 ns Â± 1.92 ns per loop (mean Â± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit document_similarity_new('assets/short.t1.txt','assets/short.t2.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 Âµs Â± 5.91 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit document_similarity_new.__wrapped__('assets/short.t1.txt','assets/short.t2.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of long text cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 ns Â± 1.11 ns per loop (mean Â± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit document_similarity_new('assets/t1.verne.txt', 'assets/t2.bobsey.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfomance of very long text cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 ns Â± 3.2 ns per loop (mean Â± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit document_similarity_new('assets/t5.churchill.txt', 'assets/t8.shakespeare.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.9 ms Â± 556 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit document_similarity_new.__wrapped__('assets/t5.churchill.txt', 'assets/t8.shakespeare.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I adjusted the assert statments because of my refactored code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result validation\n",
    "# 20 points\n",
    "\n",
    "# This check verifies that your results are correct for the short text cases.\n",
    "list1 = [(k,v) for k,v in read_file_new('assets/short.t1.txt').items()]\n",
    "list2 = [(k,v) for k,v in read_file_new('assets/short.t2.txt').items()]\n",
    "list1.sort()\n",
    "list2.sort()\n",
    "\n",
    "list1_tuple = tuple(list1)\n",
    "list2_tuple = tuple(list2)\n",
    "\n",
    "sorted_word_list_1 = list1_tuple\n",
    "sorted_word_list_2 = list2_tuple\n",
    "cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "\n",
    "def close_match(a, b):\n",
    "    return round(float(a), 3) == round(float(b), 3)\n",
    "\n",
    "assert len(sorted_word_list_1) == 772\n",
    "assert len(sorted_word_list_2) == 334\n",
    "\n",
    "assert close_match(vector_angle(sorted_word_list_1,sorted_word_list_2), 0.713)\n",
    "assert close_match(math.acos(cosine), 0.778)  # Documents angle in radians\n",
    "assert close_match(math.acos(cosine)*180/math.pi, 44.559)  # Documents angle in degrees\n",
    "\n",
    "# There are no hidden autograder tests in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In office hours and on SLACK I heard and read (I believe) that it is okay to rewrite or even ignore what is below if it is no longer relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2efa089c3ef418eaec2edb0d5260401",
     "grade": true,
     "grade_id": "cell-1a-63aea205c14ed",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-692d048cfedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msorted_word_list_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_frequencies_for_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assets/short.t1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msorted_word_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_frequencies_for_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assets/short.t2.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_word_list_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_word_list_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclose_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Result validation\n",
    "# 20 points\n",
    "\n",
    "# This check verifies that your results are correct for the short text cases.\n",
    "\n",
    "sorted_word_list_1 = word_frequencies_for_file('assets/short.t1.txt', verbose=False)\n",
    "sorted_word_list_2 = word_frequencies_for_file('assets/short.t2.txt', verbose=False)\n",
    "cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "\n",
    "def close_match(a, b):\n",
    "    return round(float(a), 3) == round(float(b), 3)\n",
    "\n",
    "assert len(sorted_word_list_1) == 772\n",
    "assert len(sorted_word_list_2) == 334\n",
    "\n",
    "assert close_match(vector_angle(sorted_word_list_1,sorted_word_list_2), 0.713)\n",
    "assert close_match(math.acos(cosine), 0.778)  # Documents angle in radians\n",
    "assert close_match(math.acos(cosine)*180/math.pi, 44.559)  # Documents angle in degrees\n",
    "\n",
    "# There are no hidden autograder tests in this cell."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_efficient_data_processing_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
